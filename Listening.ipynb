{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine: 0.45226701686664544\n"
     ]
    }
   ],
   "source": [
    "import re, math\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "\n",
    "def cosine(vec1, vec2):\n",
    "     intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "     numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "     sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "     sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "     denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "     if not denominator:\n",
    "        return 0.0\n",
    "     else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text):\n",
    "     words = WORD.findall(text)\n",
    "     return Counter(words)\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stoplist = stopwords.words('english')\n",
    "\n",
    "\n",
    "\n",
    "file1= open('text1.txt') # Reference essay which we will have in the dataset\n",
    "file2= open('text2.txt') # essay written by the candidate\n",
    "\n",
    "# Reading the both the files\n",
    "text1 = file1.read()\n",
    "text2 = file2.read()\n",
    "ps = PorterStemmer()\n",
    "# Removing the stop words and changing all the words to their roots words    \n",
    "clean = [ps.stem(word) for word in text1.split() if word not in stoplist]\n",
    "clean1 = [ps.stem(word) for word in text2.split() if word not in stoplist]\n",
    "clean=' '.join(clean)\n",
    "clean1=' '.join(clean1)\n",
    "\n",
    "#Making dicitonary of both the files\n",
    "vector1 = text_to_vector(clean)\n",
    "vector2 = text_to_vector(clean1)\n",
    "# applying cosine similarity formula\n",
    "cosine = cosine(vector1,vector2)\n",
    "    \n",
    "\n",
    "print ('Cosine:', cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine: 0.38461835500768987\n"
     ]
    }
   ],
   "source": [
    "import re, math\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "\n",
    "def cosine(vec1, vec2):\n",
    "     intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "     numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "     sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "     sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "     denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "     if not denominator:\n",
    "        return 0.0\n",
    "     else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text):\n",
    "     words = WORD.findall(text)\n",
    "     return Counter(words)\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stoplist = stopwords.words('english')\n",
    "\n",
    "\n",
    "\n",
    "file1= open('a.txt') # Reference essay which we will have in the dataset\n",
    "file2= open('b.txt') # essay written by the candidate\n",
    "\n",
    "# Reading the both the files\n",
    "text1 = file1.read()\n",
    "text2 = file2.read()\n",
    "ps = PorterStemmer()\n",
    "# Removing the stop words and changing all the words to their roots words    \n",
    "clean = [ps.stem(word) for word in text1.split() if word not in stoplist]\n",
    "clean1 = [ps.stem(word) for word in text2.split() if word not in stoplist]\n",
    "clean=' '.join(clean)\n",
    "clean1=' '.join(clean1)\n",
    "\n",
    "#Making dicitonary of both the files\n",
    "vector1 = text_to_vector(clean)\n",
    "vector2 = text_to_vector(clean1)\n",
    "# applying cosine similarity formula\n",
    "cosine = cosine(vector1,vector2)\n",
    "    \n",
    "\n",
    "print ('Cosine:', cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(vec1, vec2):\n",
    "     intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "     numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "     sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "     sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "     denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "     if not denominator:\n",
    "        return 0.0\n",
    "     else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text):\n",
    "     words = WORD.findall(text)\n",
    "     return Counter(words)\n",
    "def vocab_check(file1,file2):\n",
    "    stoplist = stopwords.words('english')\n",
    "    file1= open('text1.txt') # Reference essay which we will have in the dataset\n",
    "    file2= open('text2.txt') # essay written by the candidate\n",
    "    # Reading the both the files\n",
    "    text1 = file1.read()\n",
    "    text2 = file2.read()\n",
    "    ps = PorterStemmer()\n",
    "    # Removing the stop words and changing all the words to their roots words    \n",
    "    clean = [ps.stem(word) for word in text1.split() if word not in stoplist]\n",
    "    clean1 = [ps.stem(word) for word in text2.split() if word not in stoplist]\n",
    "    clean=' '.join(clean)\n",
    "    clean1=' '.join(clean1)\n",
    "    #Making dicitonary of both the files\n",
    "    vector1 = text_to_vector(clean)\n",
    "    vector2 = text_to_vector(clean1)\n",
    "    # applying cosine similarity formula\n",
    "    cosine1 = cosine(vector1,vector2)\n",
    "    print ('Cosine:', cosine1)\n",
    "    return cosine1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form(file1):\n",
    "    num_words = 0\n",
    "    with open(file1, 'r') as f:\n",
    "        for line in f:\n",
    "            words = line.split()\n",
    "            num_words += len(words)\n",
    "    print(\"Number of words:\")\n",
    "    print(num_words)\n",
    "    c=num_words\n",
    "    score=0\n",
    "    if(c>=50 and c<=70):\n",
    "        score=2\n",
    "    elif((c>=40)and(c<49))or(c>=71 and c<=100):\n",
    "        score=1\n",
    "    else:\n",
    "        score=0\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words:\n",
      "44\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "form(\"text1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grammar_check(text):\n",
    "#     text = 'This API are vey  good'\n",
    "    is_noun = lambda pos: pos[:3] == 'NNP'\n",
    "    tokenized = nltk.word_tokenize(text)\n",
    "    d={}\n",
    "    final_str=[]\n",
    "    for (word, pos) in nltk.pos_tag(tokenized):\n",
    "        if is_noun(pos):\n",
    "            d[tokenized.index(word)]=word\n",
    "    # print(d)\n",
    "    parser = GingerIt()\n",
    "    a=parser.parse(text+\".\")\n",
    "    check=a['result']\n",
    "    tokenized_check = nltk.word_tokenize(check)\n",
    "    # print(tokenized_check)\n",
    "    for i in range(len(tokenized_check)):\n",
    "        if i not in d:\n",
    "            final_str.append(tokenized_check[i])\n",
    "        else:\n",
    "            final_str.append(d[i])\n",
    "    print(\" \".join(final_str))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811\n"
     ]
    }
   ],
   "source": [
    "num_words = 0\n",
    " \n",
    "with open(\"a.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        words = line.split()\n",
    "        num_words += len(words)\n",
    "print(num_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gingerit.gingerit import GingerIt\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "from gensim.summarization.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content(file1,file2):\n",
    "    c=vocab_check(file1,file2)\n",
    "    score=0\n",
    "    if(c>0.4):\n",
    "        score=2\n",
    "    elif(c<0.4 and c<0.2):\n",
    "        score=1\n",
    "    else:\n",
    "        score=0\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine: 0.45226701686664544\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "content(\"a.txt\",\"b.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Story of My Life is the autobiography of Helen Keller, written when she was enrolled at Radcliffe College in her early twenties. Most readers will be familiar with parts of Keller’s story. Born in June of 1880, she went both blind and deaf at the age of nineteen months as the result of an illness that was most likely meningitis.\n",
      "\n",
      "The book begins with Keller’s earliest memories of sights and sounds. The section is indistinct, almost dreamlike in parts, which will make sense to any reader who mistrusts memories or impressions that seem to come from that far back in his or her past.\n",
      "\n",
      "Moving quickly past the early stages of the illness, the major emphasis of The Story of My Life is spent on Keller’s tutelage under Anne Sullivan. While trying to find help for Helen, her parents visit Alexander Graham Bell, who was working on behalf of deaf children at the time. (This segment of the book casts Bell in a better light than he would ultimately deserve. He was actively against the teaching of sign language in schools, and was a proponent of eugenics, and of forbidding deaf people to marry).\n",
      "\n",
      "It is through Bell that Anne Sullivan comes to arrive at the Keller’s home. Sullivan was also blind, although she was not hampered in her language acquisition as Keller was, because she could still hear. She began working with Helen when Sullivan was only twenty years old.\n",
      "\n",
      "These early sections of the book are a masterful rendition of the severe isolation that Keller felt. She was almost literally incarcerated by her lack of sensory input. Even the tool of language had been denied to her, so there was no way for her to understand her situation, because no one, prior to Sullivan, could explain things to her. Sullivan quickly begins trying to teach Helen to communicate through signing: she writes letters in Helen’s palm, attempting to get her to associate the shapes with various objects, such as a mug. Until the breakthrough moment, Helen is massively frustrated by these attempts. While Sullivan places a mug in her hand and tries to spell “mug” in her palm, Keller is so agitated by the lack of understanding that she breaks the mug into shards.\n",
      "\n",
      "The most famous instance in Keller’s story—and the many adaptations, including The Miracle Worker—is the moment when it all clicks. While running water over Keller’s palm and making the shapes for “water,” it suddenly becomes clear. Soon, Keller transforms from the paragon of frustration into an obsessive learner. She is insatiable for the knowledge that her first years prohibited her from acquiring. It is in her ambitious study that The Story of My Life illustrates one of its core themes: language is powerful, and knowledge makes peoples’ lives better.\n",
      "\n",
      "There is a power in naming things, in being able to explain one’s situation. Denied the tools of language, Keller was unable to even think clearly about her own situation, to say nothing of bonding with her parents or strategizing about her future. Part One of the book ends with her leaving for Radcliffe College, ablaze with a desire to grow and learn.\n",
      "\n",
      "Part Two comprises a series of letters written to Keller’s family and friends. It is illuminating to see someone struggle, in language, with language itself. She admits frankly that verbal speech is still awkward from her and she is unsure of her ability to measurably improve it. And so, she writes. In this way, even though Keller had already published several articles by the time of the book’s publication, The Story of My Life is a performance of the very themes it illustrates. Keller improves on the page, with every paragraph. Each installment of the book was a triumph for her.\n",
      "\n",
      "The third part of the book is a reconstruction of Keller’s life, based on the observations of the astute Sullivan, who would maintain her relationship with Helen for nearly five decades.\n",
      "\n",
      "Many books are called “inspirational” because someone has overcome something, or have rebounded from their own calamitous choices. The Story of My Life is different. Keller was born into circumstances that most readers will not be able to imagine. She does very little moping. Rather, once she sees that language will allow her to live the fullest, most fulfilling version of her life, she rushes headlong towards it and never stops trying to enrich herself and others.\n",
      "\n",
      "The Story of My Life has received great critical acclaim. Those who criticize it are often those who take issues with Keller’s later-in-life politics. She was an ardent socialist and activist, and her firebrand status has made it impossible for some who oppose her ideas to view her autobiography with objectivity. And yet, for anyone who can approach the book with an open mind, there is much to be learned here, and much…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"a.txt\", 'r') as f:\n",
    "    content=f.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lecture describes how rainbows form . This happens when white light from the sun comes direct to earth and intercept rainfall . A single drop of that rain transmits seven colors of white light , which are : violet , indigo , blue , green , yellow , orange and red . This happens at a certain angle at a certain time .\n"
     ]
    }
   ],
   "source": [
    "with open(\"text2.txt\", 'r') as f:\n",
    "    content=f.read()\n",
    "    grammar_check(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He is a bo . He is 23 years ol . He plays footbal . He likes fruit . he edges\n"
     ]
    }
   ],
   "source": [
    "grammar_check(\"He is a boy.He is 23 years old.He plays football.He likes fruits.he idjioc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are typically available within five business days . Testing globally over 360 days of the year , in over 250 test centers around the world Computer Computer based marking ensures all test takers are scored impartially and accurately .\n"
     ]
    }
   ],
   "source": [
    "grammar_check(\"Results are typically available within five business days. Testing globally over 360 days of the year, in over 250 test centers around the world. Computer based marking ensures all test takers are scored impartially and accurately.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are typically available within five business days .\n"
     ]
    }
   ],
   "source": [
    "grammar_check(\"Results are typically available within five business days.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing globally over 360 days of the year , in over 250 test centers around the world .\n"
     ]
    }
   ],
   "source": [
    "grammar_check(\"Testing globally over 360 days of the year, in over 250 test centers around the world.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer based marking ensures all test takers are scored impartially and accurately .\n"
     ]
    }
   ],
   "source": [
    "grammar_check(\"Computer based marking ensures all test takers are scored impartially and accurately.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
